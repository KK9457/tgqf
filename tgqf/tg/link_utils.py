# -*- coding: utf-8 -*-
# tg/link_utils.py
from __future__ import annotations

from typing import List, Tuple, Optional, Callable, Awaitable
import asyncio
import re
from html import unescape as html_unescape
import inspect

from telethon import TelegramClient, functions
from telethon import errors as TE
from telethon.errors import ChannelPrivateError, InviteHashInvalidError, InviteRequestSentError
from core.telethon_errors import unwrap_error
from unified.context import get_client_manager
from unified.trace_context import get_log_context
from typess.link_types import ParsedLink, LinkType
from tg.entity_utils import get_input_entity_strict, resolve_marked_peer
from unified.logger import log_debug, log_warning, log_exception
from unified.config import MAX_CONCURRENCY
from typess.health_types import HealthState

__all__ = [
    "normalize_link", "key_from_parsed", "standardize_and_dedup_links",
    "parse_group_links", "parse_links_with_interval", "check_single_link_availability",
    "check_links_availability", "mark_username_not_occupied",
]

# ---------- å†…éƒ¨ï¼šæ¸…æ´—ç›¸å…³æ­£åˆ™ ----------
_HREF_RE = re.compile(r'href\s*=\s*["\']([^"\']+)["\']', re.I)
_TAG_RE = re.compile(r"<[^>]+>")
_MULTI_TME_RE = re.compile(r"(https?://)?t\.me/(https?://)?t\.me/", re.I)
_ZERO_WIDTH = (
    "\u200b", "\u200c", "\u200d", "\ufeff", "\u2060",
    "\u202a", "\u202b", "\u202c", "\u202d", "\u202e",
    "\u2066", "\u2067", "\u2068", "\u2069"
)

def _extract_href_or_text(raw: str) -> str:
    """æå– href å†…å®¹æˆ–æ¸…é™¤ HTML æ ‡ç­¾"""
    match = _HREF_RE.search(raw or "")
    return match.group(1) if match else _TAG_RE.sub("", raw or "")

def _strip_tme_prefix(s: str) -> str:
    """ä¿®å¤ t.me//username ç±»å¼‚å¸¸é“¾æ¥"""
    return s.replace("://t.me//", "://t.me/")

def _sanitize_raw_link(raw: str) -> str:
    """å¼ºåŠ›æ¸…æ´—åŸå§‹æ–‡æœ¬æˆæ ‡å‡†åŒ–é“¾æ¥"""
    s = html_unescape((raw or "").strip())
    s = _extract_href_or_text(s)

    # å»ç©ºç™½ä¸æ§åˆ¶å­—ç¬¦
    for ch in (" ", "\t", "\r", "\n", "â€‰", *(_ZERO_WIDTH or ())):
        s = s.replace(ch, "")

    # å¤„ç† @username â†’ username
    if s.startswith("@") and len(s) > 1:
        s = s[1:]

    # ç»Ÿä¸€ä¿®æ­£é“¾æ¥
    s = s.replace("telegram.me/", "t.me/").replace("telegram.dog/", "t.me/")
    s = _MULTI_TME_RE.sub("t.me/", s).replace("http://", "https://")
    s = s.replace("t.me/s/", "t.me/")

    # è‹¥ä»¥ t.me/ å¼€å¤´ä½†æ²¡åè®®ï¼Œè¡¥ https://
    if s.startswith("t.me/"):
        s = "https://" + s

    return _strip_tme_prefix(s)

async def _redis_setex_compat(redis, key: str, seconds: int, value: str) -> None:
    """å…¼å®¹ redis.asyncio.Redisï¼ˆéœ€è¦ awaitï¼‰ä¸åŒæ­¥ Redis å®¢æˆ·ç«¯ã€‚"""
    if not redis:
        return
    try:
        res = redis.setex(key, seconds, value)
        if inspect.isawaitable(res):
            await res
    except Exception:
        pass

def _is_placeholder_link(s: str) -> bool:
    ss = (s or "").strip().lower()
    return ss in {"-", "t.me/-", "https://t.me/-", "@-"}



# ---------- è§£æä¸è§„èŒƒåŒ– ----------
def normalize_link(raw: str) -> ParsedLink:
    """å¼ºåŠ›æ¸…æ´—å¹¶ä½¿ç”¨ ParsedLink è§£æ"""
    s = _sanitize_raw_link(raw)
    log_debug("å¼€å§‹è§£æé“¾æ¥", extra={"raw": raw, "sanitized": s, **(get_log_context() or {})})

    # ğŸš« ä¸¢å¼ƒå ä½/æ— æ•ˆ â€œ-â€ é“¾æ¥ï¼Œé˜²æ­¢è¿›å…¥åç»­åˆ†é…/ç»Ÿè®¡
    if _is_placeholder_link(s):
        raise ValueError("ã€æ¸…æ´—é“¾æ¥ã€‘ æ£€æµ‹åˆ°å ä½ç¬¦ '-' ")

    try:
        return ParsedLink.parse(s)
    except Exception as e:
        log_exception("âŒã€æ¸…æ´—é“¾æ¥ã€‘ è§£æé“¾æ¥å¤±è´¥", exc=e, extra={"sanitized": s, **(get_log_context() or {})})
        raise ValueError(f"ã€æ¸…æ´—é“¾æ¥ã€‘ æ— æ³•è§£æé“¾æ¥æ ¼å¼: {s} ({type(e).__name__}: {e})") from e

# å…¼å®¹å±‚ï¼šå¯¹å¤–ä»æä¾› key_from_parsedï¼Œä½†å†…éƒ¨ç»Ÿä¸€ä½¿ç”¨ ParsedLink.cache_key() ä½œä¸ºå¼º key
def key_from_parsed(pl: ParsedLink) -> str:
    """ç”¨äºå†å²å…¼å®¹ï¼šè¿”å›çŸ­ keyï¼ˆä¸å«ç±»å‹å‰ç¼€ï¼‰"""
    return pl.short()

def _strong_key(pl: ParsedLink) -> str:
    """å†…éƒ¨ä½¿ç”¨çš„å¼º keyï¼Œå¸¦ç±»å‹å‰ç¼€ï¼Œé¿å…è·¨ç±»å‹ç¢°æ’"""
    return pl.cache_key()

def standardize_and_dedup_links(raw_lines: List[str]) -> List[Tuple[str, ParsedLink]]:
    """æ ‡å‡†åŒ–å¹¶å»é‡åŸå§‹é“¾æ¥ï¼ˆæŒ‰å¼º key å»é‡ï¼‰"""
    seen_keys = set()
    results: List[Tuple[str, ParsedLink]] = []

    for raw in raw_lines:
        try:
            pl = normalize_link(raw)
            if not pl.is_valid():
                continue
            key = _strong_key(pl)
            if key not in seen_keys:
                seen_keys.add(key)
                results.append((raw, pl))
        except Exception:
            continue
    return results

async def parse_group_links(group_list: List[str]) -> List[ParsedLink]:
    """å¿«é€Ÿæ‰¹é‡è§£æï¼ˆæ— èŠ‚æµï¼‰"""
    return [pl for _, pl in standardize_and_dedup_links(group_list)]

async def parse_links_with_interval(group_list: List[str], interval: float = 0.5) -> List[ParsedLink]:
    """æ‰¹é‡è§£æé“¾æ¥ï¼Œå¹¶æŒ‰é—´éš”æ‰§è¡Œä»¥èŠ‚æµ"""
    links = []
    for _, pl in standardize_and_dedup_links(group_list):
        links.append(pl)
        await asyncio.sleep(interval)
    return links

def _mask_invite(code: str) -> str:
    return code[:3] + "***" + code[-3:] if len(code) > 6 else "***"

# ---------- å¯ç”¨æ€§é¢„æ£€ ----------
async def mark_username_not_occupied(
    redis,
    user_id: Optional[int],
    uname: Optional[str],
    e: Exception,
    link: ParsedLink,
    on_username_invalid: Optional[Callable[[str], Awaitable[None]]] = None
) -> str:
    """æ ‡è®°ç”¨æˆ·åä¸ºæœªè¢«å ç”¨å¹¶ç¼“å­˜"""
    if not uname:
        return "Username missing"
    await _redis_setex_compat(redis, f"user:{user_id}:tg:username_not_occupied:{uname}", 24 * 3600, "1")
    if on_username_invalid:
        try:
            await on_username_invalid(uname)
        except Exception:
            pass
    log_warning("âŒæ— æ•ˆç”¨æˆ·å", extra={"username": uname, "reason": str(e), "link": link.to_link()})
    return f"UsernameNotOccupied: {uname}"

async def check_single_link_availability(
    client: TelegramClient,
    link: ParsedLink,
    *,
    redis=None,
    user_id: Optional[int] = None,
    # å¯é€‰ï¼šè‹¥ä½ è¦åœ¨è¿™é‡Œç›´æ¥æŠŠ client æ ‡æˆ AUTH_EXPIREDï¼Œå°±æŠŠè¿™ä¸¤é¡¹ä¼ è¿›æ¥
    client_manager=None,
    phone: Optional[str] = None,
    skip_invite_check: bool = False,
    on_username_invalid: Optional[Callable[[str], Awaitable[None]]] = None
) -> Tuple[bool, Optional[str]]:
    """æ£€æŸ¥å•ä¸ªé“¾æ¥çš„å¯ç”¨æ€§ï¼ˆç¡®ä¿ä»»ä½•è·¯å¾„éƒ½æœ‰è¿”å›ï¼Œé˜²æ­¢ None è§£åŒ…é”™è¯¯ï¼‰"""
    try:
        # ä¿éšœï¼šclient å·²è¿æ¥ä¸” get_me æ­£å¸¸ï¼ˆé˜²æ­¢æœªæˆæƒ client ç›´æ¥è·‘è§£æï¼‰
        if not client.is_connected():
            await client.connect()
        # å¯é€‰å°è¶…æ—¶ï¼Œé¿å…å¡ä½
        try:
            await asyncio.wait_for(client.get_me(), timeout=5)
        except asyncio.TimeoutError:
            return False, "client_timeout"
        # é‚€è¯·é“¾æ¥
        if link.type == LinkType.INVITE and not skip_invite_check:
            invite_hash = str(link.value)
            await client(functions.messages.CheckChatInviteRequest(invite_hash))
            log_debug("âœ…ã€æ£€æŸ¥é“¾æ¥ã€‘æœ‰æ•ˆé‚€è¯·é“¾æ¥", extra={"code": _mask_invite(invite_hash), "user_id": user_id, **(get_log_context() or {})})
            return True, None

        # å…¬å¼€ä¼šè¯
        if link.type == LinkType.PUBLIC:
            uname = link.username or ""
            await get_input_entity_strict(client, uname)
            log_debug("âœ…ã€æ£€æŸ¥é“¾æ¥ã€‘æœ‰æ•ˆå…¬å¼€é“¾æ¥", extra={"username": uname, "user_id": user_id, **(get_log_context() or {})})
            return True, None

        # å…¬å¼€æ¶ˆæ¯æ‰€å±ä¼šè¯
        if link.type == LinkType.PUBLIC_MSG:
            uname, _mid = link.value  # noqa: F841
            await get_input_entity_strict(client, str(uname))
            log_debug("âœ…ã€æ£€æŸ¥é“¾æ¥ã€‘æœ‰æ•ˆæ¶ˆæ¯é“¾æ¥", extra={"username": uname, "user_id": user_id, **(get_log_context() or {})})
            return True, None

        # /c/<id>/<mid> æ‰€å±ä¼šè¯
        if link.type == LinkType.CHANNEL_MSG:
            cid, _mid = link.value  # noqa: F841
            peer_id = int(f"-100{cid}")
            await get_input_entity_strict(client, peer_id)
            log_debug("âœ…ã€æ£€æŸ¥é“¾æ¥ã€‘æœ‰æ•ˆ chat ID", extra={"link": link.to_link(), "user_id": user_id, **(get_log_context() or {})})
            return True, None

        # æ•°å­— ID
        if link.type == LinkType.USERID:
            try:
                val = int(link.value)
                peer_or_id = resolve_marked_peer(val) if str(val).startswith("-") else val
                await get_input_entity_strict(client, peer_or_id)
                log_debug("âœ…ã€æ£€æŸ¥é“¾æ¥ã€‘æœ‰æ•ˆ chat ID", extra={"id": str(val), "user_id": user_id, **(get_log_context() or {})})
                return True, None
            except Exception:
                log_debug("â„¹ï¸ã€æ£€æŸ¥é“¾æ¥ã€‘æœªçŸ¥ chat ID", extra={"id": str(link.value), "user_id": user_id, **(get_log_context() or {})})
                return True, None

        # chat_idï¼ˆ-100 å‰ç¼€æˆ–çº¯ chat_idï¼‰
        if link.type == LinkType.CHAT_ID:
            try:
                val = int(link.value)
                # å…è®¸ä¼  -100xxxx æˆ– xxxxï¼Œäº¤ç»™ä¸¥æ ¼è§£æå¤„ç†
                peer = val if str(val).startswith("-100") else int(f"-100{val}")
                await get_input_entity_strict(client, peer)
                log_debug("âœ…ã€æ£€æŸ¥é“¾æ¥ã€‘æœ‰æ•ˆ chat ID", extra={"chat_id": str(val), "user_id": user_id, **(get_log_context() or {})})
                return True, None
            except Exception as e:
                log_warning("â„¹ï¸ã€æ£€æŸ¥é“¾æ¥ã€‘è§£æå¤±è´¥", extra={"chat_id": str(link.value), "err": str(e), "user_id": user_id, **(get_log_context() or {})})
                return True, None

        # æœªè¯†åˆ«ç±»å‹ï¼šä¿å®ˆæ”¾è¡Œ
        log_debug("â„¹ï¸ã€æ£€æŸ¥é“¾æ¥ã€‘æ— æ³•è¯†åˆ«ï¼Œä¿å®ˆæ”¾è¡Œ", extra={"type": link.type.value, "user_id": user_id, **(get_log_context() or {})})
        return True, None

    except (TE.FloodWaitError, InviteHashInvalidError, ChannelPrivateError, InviteRequestSentError) as e:
        log_warning("âŒ ã€æ£€æŸ¥é“¾æ¥ã€‘ä¸å¯ç”¨é“¾æ¥", extra={"link": link.to_link(), "reason": str(e), "user_id": user_id, **(get_log_context() or {})})

        return False, f"{type(e).__name__}: {e}"
    except Exception as e:
        e0 = unwrap_error(e)
        # æœªæˆæƒ / å¯†é’¥æœªæ³¨å†Œ / ä¼šè¯é‡å¤ä½¿ç”¨ç­‰ â†’ æç¤ºä¸Šå±‚æ›´æ¢ client
        if isinstance(e0, (TE.AuthKeyUnregisteredError, TE.AuthKeyDuplicatedError)):
            # å¯é€‰ï¼šè‹¥ä¼ å…¥ client_manager & phoneï¼Œå¯åœ¨æ­¤ç›´æ¥æ ‡è®° AUTH_EXPIRED
            if client_manager and user_id is not None and phone is not None:
                try:
                    client_manager.set_health_state(user_id, phone, HealthState.AUTH_EXPIRED)
                except Exception:
                    pass
            log_warning("âŒã€æ£€æŸ¥é“¾æ¥ã€‘å¼‚å¸¸è´¦å·ï¼šå¯†é’¥å¤±æ•ˆ",
                        extra={"err": type(e0).__name__, "link": link.to_link(), **(get_log_context() or {})})
            return False, f"{type(e0).__name__}"
        # å…¶å®ƒï¼šè®°å½•å¹¶å›ä¼ é€šç”¨é”™è¯¯ç ï¼Œå‡å°‘çˆ†æ ˆ
        log_exception(" ã€æ£€æŸ¥é“¾æ¥ã€‘å¼‚å¸¸é”™è¯¯", exc=e0,
                      extra={"link": link.to_link(), **(get_log_context() or {})})
        return False, f"{type(e0).__name__}"
    
async def check_links_availability(
    client: TelegramClient,
    groups: List[ParsedLink],
    *,
    max_concurrency: int = MAX_CONCURRENCY,
    skip_invite_check: bool = True,
    redis=None,
    user_id: Optional[int] = None,
    on_username_invalid: Optional[Callable[[str], Awaitable[None]]] = None
) -> Tuple[List[ParsedLink], List[Tuple[ParsedLink, str]]]:
    """å¹¶å‘æ£€æŸ¥å¤šä¸ªé“¾æ¥çš„å¯ç”¨æ€§ï¼ˆfail-open ä¸åœ¨æ­¤å¤„ï¼Œå¤±è´¥ç›´æ¥è®¡å…¥ invalidï¼‰"""
    client_manager = get_client_manager()
    # å”¯ä¸€åŒ–ï¼ˆå¼º keyï¼‰
    seen = set()
    uniq: List[ParsedLink] = []
    for pl in groups:
        if not isinstance(pl, ParsedLink):
            continue
        k = _strong_key(pl)
        if k in seen:
            continue
        seen.add(k)
        uniq.append(pl)

    if not uniq:
        return [], []

    sem = asyncio.Semaphore(max(1, int(max_concurrency or 5)))
    results: List[Tuple[ParsedLink, bool, Optional[str]]] = []

    async def worker(pl: ParsedLink) -> None:
        async with sem:
            ok, reason = await check_single_link_availability(
                client, pl,
                redis=redis,
                user_id=user_id,
                client_manager=client_manager,   # å¯é€‰ï¼šè‹¥åœ¨ç±»æ–¹æ³•é‡Œ
                phone=getattr(client, "phone", None), # å¯é€‰
                skip_invite_check=skip_invite_check,
                on_username_invalid=on_username_invalid
            )
            # å§‹ç»ˆä¸‰å…ƒç»„ï¼Œé¿å… None è§£åŒ…
            results.append((pl, bool(ok), (None if ok else (reason or "unknown"))))

    tasks = [asyncio.create_task(worker(pl)) for pl in uniq]
    await asyncio.gather(*tasks)

    valid = [pl for pl, ok, _ in results if ok]
    invalid = [(pl, reason or "unknown") for pl, ok, reason in results if not ok]

    log_debug(
        "ğŸ” ã€å¹¶å‘æ£€æŸ¥é“¾æ¥ã€‘å®Œæˆ",
        extra={
            "input": len(groups),
            "unique": len(uniq),
            "valid": len(valid),
            "invalid": len(invalid),
            **(get_log_context() or {})
        },
    )
    return valid, invalid
